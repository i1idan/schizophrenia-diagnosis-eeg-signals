{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec06fe58",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/i1idan/schizophrenia-diagnosis-eeg-signals/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B7YlhS4gYc8s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B7YlhS4gYc8s",
    "outputId": "7ed228ec-718f-43ae-bf46-9511ead2581e"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FB7LuLHBlpvM",
   "metadata": {
    "id": "FB7LuLHBlpvM"
   },
   "source": [
    "# Clone the Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d35c532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d35c532",
    "outputId": "cb3b1d58-fdfb-48f5-9fa6-dadc8a12fc24"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/i1idan/schizophrenia-diagnosis-eeg-signals.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6X3Blwu5ZKWq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6X3Blwu5ZKWq",
    "outputId": "77e2207f-1941-4df9-d692-dd19d7811671"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/schizophrenia-diagnosis-eeg-signals')\n",
    "!git pull origin main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pfZzZofyZVB_",
   "metadata": {
    "id": "pfZzZofyZVB_"
   },
   "source": [
    "# Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3uUKOYfZUiA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f3uUKOYfZUiA",
    "outputId": "1e927faf-42ef-421a-f8e8-7d640bfb6b07"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lCirzbPuZyuQ",
   "metadata": {
    "id": "lCirzbPuZyuQ"
   },
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tsJQv-K5Z0k-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsJQv-K5Z0k-",
    "outputId": "87b9103c-18b2-4af4-ab91-2797b4e663e3"
   },
   "outputs": [],
   "source": [
    "!gdown --id 1jnWHWrArzJQIvny0cQkfPP42hEJAp_56\n",
    "!mv DATA.mat /content/schizophrenia-diagnosis-eeg-signals/data/DATA.mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4130c324",
   "metadata": {
    "id": "4130c324"
   },
   "source": [
    "# Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98c9e21c",
   "metadata": {
    "id": "98c9e21c"
   },
   "outputs": [],
   "source": [
    "# Number of training in a sequence\n",
    "multi_train = 10\n",
    "epochs = 200\n",
    "model_name = \"WaveletCustom\"\n",
    "data_path = \"./data/DATA.mat\"\n",
    "# checkpoints = \"/content/drive/MyDrive/schizophrenia/checkpoints\"\n",
    "checkpoints = \"./checkpoints\"\n",
    "batch_size = 4\n",
    "early_stopping = 100\n",
    "reduce_lr = 50\n",
    "seed = 1234"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf6ef6b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4bf6ef6b",
    "outputId": "87919b59-9c9b-4601-d6a1-c93a5e63b286",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model:WaveletCustom is loaded ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 110, 110, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 108, 108, 8)       80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 107, 107, 8)       264       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 53, 53, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 53, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 16)        528       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 51, 51, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 23, 23, 32)        4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                991264    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,007,673\n",
      "Trainable params: 1,007,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Loading 2d data\n",
      "[INFO] H.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,)\n",
      "[INFO] CHAN.shape: (1, 19)\n",
      "[INFO] Fs.shape: (1, 1)\n",
      "[INFO] healthy_samples: 14, schizo_samples: 14, channel_size: 19, and sub: 15000\n",
      "[INFO] normal samples: (532, 112, 112)\n",
      "[INFO] schizo samples: (532, 112, 112)\n",
      "[INFO] labels: (1064,)\n",
      "[INFO] data: (1064, 112, 112, 1)\n",
      "[INFO] x_train.shape: (851, 112, 112, 1), y_train.shape: (851,)\n",
      "[INFO] x_test.shape: (213, 112, 112, 1), y_test.shape: (213,)\n",
      "[INFO] Started the training for model: WaveletCustom ...\n",
      "[INFO] Saving params!\n",
      "[INFO] Params are successfully saved!\n",
      "[INFO] Training with the following arguments Namespace(seed=1234, model_name='WaveletCustom', data_path='./data/DATA.mat', epochs=200, batch_size=4, checkpoints='./checkpoints', early_stopping=100, reduce_lr=50, dir_name='0')\n",
      "Epoch 1/200\n",
      "213/213 [==============================] - 5s 13ms/step - loss: 0.6085 - accuracy: 0.6686 - val_loss: 0.5610 - val_accuracy: 0.7277 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.5391 - accuracy: 0.7333 - val_loss: 0.5310 - val_accuracy: 0.7371 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4748 - accuracy: 0.7685 - val_loss: 0.5302 - val_accuracy: 0.7746 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4412 - accuracy: 0.7720 - val_loss: 0.4940 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.3897 - accuracy: 0.8049 - val_loss: 0.4364 - val_accuracy: 0.7934 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.3454 - accuracy: 0.8378 - val_loss: 0.3765 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2918 - accuracy: 0.8778 - val_loss: 0.3949 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.2467 - accuracy: 0.8872 - val_loss: 0.3362 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.2517 - accuracy: 0.8825 - val_loss: 0.3289 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1941 - accuracy: 0.9142 - val_loss: 0.3460 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9318 - val_loss: 0.3757 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1454 - accuracy: 0.9412 - val_loss: 0.3702 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.1372 - accuracy: 0.9424 - val_loss: 0.2717 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1423 - accuracy: 0.9412 - val_loss: 0.3427 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1442 - accuracy: 0.9459 - val_loss: 0.3621 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.1124 - accuracy: 0.9600 - val_loss: 0.5260 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.1214 - accuracy: 0.9659 - val_loss: 0.2185 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0618 - accuracy: 0.9753 - val_loss: 0.2321 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1104 - accuracy: 0.9589 - val_loss: 0.2389 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0704 - accuracy: 0.9765 - val_loss: 0.2597 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.1069 - accuracy: 0.9730 - val_loss: 0.1968 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1017 - accuracy: 0.9694 - val_loss: 0.2496 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.1088 - accuracy: 0.9683 - val_loss: 0.1802 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0514 - accuracy: 0.9788 - val_loss: 0.2644 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0595 - accuracy: 0.9871 - val_loss: 0.1780 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9835 - val_loss: 0.2403 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9730 - val_loss: 0.2079 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0494 - accuracy: 0.9871 - val_loss: 0.1831 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0384 - accuracy: 0.9859 - val_loss: 0.1452 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0406 - accuracy: 0.9812 - val_loss: 0.1856 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0667 - accuracy: 0.9765 - val_loss: 0.1804 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0470 - accuracy: 0.9812 - val_loss: 0.1445 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 0.9788 - val_loss: 0.1495 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0615 - accuracy: 0.9800 - val_loss: 0.1081 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0699 - accuracy: 0.9847 - val_loss: 0.1297 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0870 - accuracy: 0.9600 - val_loss: 0.1854 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0214 - accuracy: 0.9929 - val_loss: 0.0875 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0456 - accuracy: 0.9859 - val_loss: 0.0687 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0506 - accuracy: 0.9847 - val_loss: 0.1846 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0682 - accuracy: 0.9847 - val_loss: 0.2359 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0488 - accuracy: 0.9824 - val_loss: 0.0684 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0371 - accuracy: 0.9812 - val_loss: 0.0852 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9871 - val_loss: 0.1012 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0323 - accuracy: 0.9918 - val_loss: 0.3212 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9859 - val_loss: 0.0933 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9929 - val_loss: 0.0823 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9894 - val_loss: 0.1200 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9765 - val_loss: 0.1114 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0578 - accuracy: 0.9859 - val_loss: 0.0840 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0225 - accuracy: 0.9929 - val_loss: 0.0973 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0287 - accuracy: 0.9906 - val_loss: 0.0575 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0266 - accuracy: 0.9918 - val_loss: 0.0861 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9882 - val_loss: 0.2594 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0148 - accuracy: 0.9965 - val_loss: 0.1062 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9976 - val_loss: 0.2153 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9906 - val_loss: 0.1028 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0420 - accuracy: 0.9847 - val_loss: 0.1003 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0382 - accuracy: 0.9894 - val_loss: 0.1166 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0427 - accuracy: 0.9894 - val_loss: 0.1396 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9929 - val_loss: 0.1829 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0692 - accuracy: 0.9882 - val_loss: 0.1309 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0266 - accuracy: 0.9929 - val_loss: 0.0917 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0488 - accuracy: 0.9871 - val_loss: 0.1612 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0332 - accuracy: 0.9871 - val_loss: 0.1208 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0252 - accuracy: 0.9894 - val_loss: 0.1242 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0235 - accuracy: 0.9953 - val_loss: 0.0828 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.0647 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9976 - val_loss: 0.1057 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0089 - accuracy: 0.9976 - val_loss: 0.0780 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0203 - accuracy: 0.9953 - val_loss: 0.1237 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.1193 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9882 - val_loss: 0.1457 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9941 - val_loss: 0.1083 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0165 - accuracy: 0.9965 - val_loss: 0.0437 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0431 - accuracy: 0.9871 - val_loss: 0.1773 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0526 - accuracy: 0.9859 - val_loss: 0.0461 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 0.0542 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0995 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0331 - accuracy: 0.9906 - val_loss: 0.0672 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9929 - val_loss: 0.1713 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.0923 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.0844 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0412 - accuracy: 0.9871 - val_loss: 0.0727 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0521 - accuracy: 0.9906 - val_loss: 0.0785 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0113 - accuracy: 0.9976 - val_loss: 0.0933 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9953 - val_loss: 0.0820 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.1759 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0487 - accuracy: 0.9918 - val_loss: 0.0990 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.0613 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "213/213 [==============================] - 3s 13ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0410 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.1351 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0283 - accuracy: 0.9871 - val_loss: 0.3502 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9694 - val_loss: 0.0889 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0197 - accuracy: 0.9906 - val_loss: 0.0546 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0076 - val_accuracy: 1.0000 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.0324 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0099 - accuracy: 0.9976 - val_loss: 0.0098 - val_accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0115 - accuracy: 0.9941 - val_loss: 0.0375 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9953 - val_loss: 0.0832 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0321 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0174 - accuracy: 0.9965 - val_loss: 0.0375 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9976 - val_loss: 0.0111 - val_accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.1047 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.0264 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0380 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0532 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9988 - val_loss: 0.0273 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0774 - accuracy: 0.9824 - val_loss: 0.1629 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0883 - accuracy: 0.9800 - val_loss: 0.1152 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0281 - accuracy: 0.9965 - val_loss: 0.0275 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0051 - accuracy: 0.9988 - val_loss: 0.0210 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9941 - val_loss: 0.1347 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0970 - accuracy: 0.9824 - val_loss: 0.0575 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 114/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0274 - accuracy: 0.9894 - val_loss: 0.0260 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0185 - accuracy: 0.9953 - val_loss: 0.0293 - val_accuracy: 0.9953 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9918 - val_loss: 0.0728 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 0.0607 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0882 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9988 - val_loss: 0.0942 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9976 - val_loss: 0.1437 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0245 - accuracy: 0.9941 - val_loss: 0.1305 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9953 - val_loss: 0.0423 - val_accuracy: 0.9906 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9929 - val_loss: 0.0390 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.0610 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0549 - accuracy: 0.9847 - val_loss: 0.0703 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0139 - accuracy: 0.9953 - val_loss: 0.1012 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0818 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9941 - val_loss: 0.0565 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.1275 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0232 - accuracy: 0.9941 - val_loss: 0.1079 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0292 - accuracy: 0.9965 - val_loss: 0.1862 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0635 - accuracy: 0.9953 - val_loss: 0.1426 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 133/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9941 - val_loss: 0.0943 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0863 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9965 - val_loss: 0.0734 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9918 - val_loss: 0.0294 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9976 - val_loss: 0.0489 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0363 - accuracy: 0.9929 - val_loss: 0.0984 - val_accuracy: 0.9765 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0296 - accuracy: 0.9941 - val_loss: 0.0419 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9953 - val_loss: 0.0334 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.0578 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9929 - val_loss: 0.0502 - val_accuracy: 0.9812 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0064 - accuracy: 0.9965 - val_loss: 0.0324 - val_accuracy: 0.9859 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9965 - val_loss: 0.2010 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "208/213 [============================>.] - ETA: 0s - loss: 0.0187 - accuracy: 0.9928\n",
      "Epoch 00145: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0184 - accuracy: 0.9929 - val_loss: 0.1184 - val_accuracy: 0.9718 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0382 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 147/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9988 - val_loss: 0.0349 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 148/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 149/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.9104e-04 - accuracy: 1.0000 - val_loss: 0.0261 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 150/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0187 - accuracy: 0.9976 - val_loss: 0.1225 - val_accuracy: 0.9624 - lr: 5.0000e-04\n",
      "Epoch 151/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.1161 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 152/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0024 - accuracy: 0.9988 - val_loss: 0.0914 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 153/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 0.1082 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 2.8637e-04 - accuracy: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.0611 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0023 - accuracy: 0.9988 - val_loss: 0.0579 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.1371 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0109 - accuracy: 0.9988 - val_loss: 0.1471 - val_accuracy: 0.9671 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9976 - val_loss: 0.1305 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 5.5629e-04 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 7.7147e-04 - accuracy: 1.0000 - val_loss: 0.0909 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 9.6035e-04 - accuracy: 0.9988 - val_loss: 0.1051 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0072 - accuracy: 0.9976 - val_loss: 0.0633 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 164/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.0431 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 7.9352e-05 - accuracy: 1.0000 - val_loss: 0.0237 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0071 - accuracy: 0.9965 - val_loss: 0.0189 - val_accuracy: 0.9953 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9953 - val_loss: 0.1621 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 6.9396e-04 - accuracy: 1.0000 - val_loss: 0.1484 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0048 - accuracy: 0.9988 - val_loss: 0.0233 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.1017 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0713 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.1245 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 3.0380e-04 - accuracy: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.0869e-05 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.0891e-04 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 3.4699e-05 - accuracy: 1.0000 - val_loss: 0.0861 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 5.0713e-04 - accuracy: 1.0000 - val_loss: 0.1412 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0034 - accuracy: 0.9976 - val_loss: 0.1600 - val_accuracy: 0.9671 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 7.6496e-05 - accuracy: 1.0000 - val_loss: 0.1269 - val_accuracy: 0.9671 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 6.9380e-05 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 1.7584e-05 - accuracy: 1.0000 - val_loss: 0.0992 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 182/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 6ms/step - loss: 8.2491e-05 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9765 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0012 - accuracy: 0.9988 - val_loss: 0.0221 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 1.5037e-05 - accuracy: 1.0000 - val_loss: 0.0211 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 1.5591e-05 - accuracy: 1.0000 - val_loss: 0.0213 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.2639e-04 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 1.5118e-04 - accuracy: 1.0000 - val_loss: 0.0168 - val_accuracy: 0.9906 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 0.2114 - val_accuracy: 0.9577 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0269 - accuracy: 0.9953 - val_loss: 0.0475 - val_accuracy: 0.9859 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0535 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.0753 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.1432 - val_accuracy: 0.9718 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9988 - val_loss: 0.1234 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0318 - accuracy: 0.9941 - val_loss: 0.1066 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "207/213 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9988\n",
      "Epoch 00195: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.1102 - val_accuracy: 0.9812 - lr: 5.0000e-04\n",
      "Epoch 00195: early stopping\n",
      "[INFO] confusion matrix:!\n",
      "[INFO] Loading best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       106\n",
      "         1.0       1.00      1.00      1.00       107\n",
      "\n",
      "    accuracy                           1.00       213\n",
      "   macro avg       1.00      1.00      1.00       213\n",
      "weighted avg       1.00      1.00      1.00       213\n",
      "\n",
      "[INFO] Computing Confusion matrix\n",
      "conf_matrix.jpg is successfully saved!\n",
      "-----------------------------train 0 is done! ----------------------------------\n",
      "[INFO] Model:WaveletCustom is loaded ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 110, 110, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 108, 108, 8)       80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 107, 107, 8)       264       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 53, 53, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 53, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 16)        528       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 51, 51, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 23, 23, 32)        4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                991264    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,007,673\n",
      "Trainable params: 1,007,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Loading 2d data\n",
      "[INFO] H.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,)\n",
      "[INFO] CHAN.shape: (1, 19)\n",
      "[INFO] Fs.shape: (1, 1)\n",
      "[INFO] healthy_samples: 14, schizo_samples: 14, channel_size: 19, and sub: 15000\n",
      "[INFO] normal samples: (532, 112, 112)\n",
      "[INFO] schizo samples: (532, 112, 112)\n",
      "[INFO] labels: (1064,)\n",
      "[INFO] data: (1064, 112, 112, 1)\n",
      "[INFO] x_train.shape: (851, 112, 112, 1), y_train.shape: (851,)\n",
      "[INFO] x_test.shape: (213, 112, 112, 1), y_test.shape: (213,)\n",
      "[INFO] Started the training for model: WaveletCustom ...\n",
      "[INFO] Saving params!\n",
      "[INFO] Params are successfully saved!\n",
      "[INFO] Training with the following arguments Namespace(seed=1235, model_name='WaveletCustom', data_path='./data/DATA.mat', epochs=200, batch_size=4, checkpoints='./checkpoints', early_stopping=100, reduce_lr=50, dir_name='1')\n",
      "Epoch 1/200\n",
      "213/213 [==============================] - 5s 15ms/step - loss: 0.6498 - accuracy: 0.6416 - val_loss: 0.5927 - val_accuracy: 0.6948 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "213/213 [==============================] - 3s 14ms/step - loss: 0.5253 - accuracy: 0.7286 - val_loss: 0.5818 - val_accuracy: 0.6948 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.4724 - accuracy: 0.7615 - val_loss: 0.5277 - val_accuracy: 0.7324 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.4334 - accuracy: 0.8026 - val_loss: 0.5461 - val_accuracy: 0.7559 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 0.4151 - accuracy: 0.8155 - val_loss: 0.5087 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.3559 - accuracy: 0.8461 - val_loss: 0.5650 - val_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.3333 - accuracy: 0.8637 - val_loss: 0.5141 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.3202 - accuracy: 0.8672 - val_loss: 0.4851 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.2714 - accuracy: 0.8895 - val_loss: 0.5010 - val_accuracy: 0.8028 - lr: 0.0010\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 2s 12ms/step - loss: 0.3005 - accuracy: 0.8813 - val_loss: 0.4143 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.2253 - accuracy: 0.9107 - val_loss: 0.4026 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.2031 - accuracy: 0.9283 - val_loss: 0.3977 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.2133 - accuracy: 0.9248 - val_loss: 0.3681 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1665 - accuracy: 0.9307 - val_loss: 0.5062 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 0.1715 - accuracy: 0.9342 - val_loss: 0.3537 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1584 - accuracy: 0.9436 - val_loss: 0.5024 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1277 - accuracy: 0.9553 - val_loss: 0.7879 - val_accuracy: 0.8122 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.1039 - accuracy: 0.9589 - val_loss: 0.4233 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0904 - accuracy: 0.9659 - val_loss: 0.7063 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.1317 - accuracy: 0.9471 - val_loss: 0.4690 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1341 - accuracy: 0.9436 - val_loss: 0.6697 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0731 - accuracy: 0.9730 - val_loss: 0.5035 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0818 - accuracy: 0.9741 - val_loss: 0.7203 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0891 - accuracy: 0.9718 - val_loss: 0.4578 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9812 - val_loss: 0.5335 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0577 - accuracy: 0.9788 - val_loss: 0.5681 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0598 - accuracy: 0.9812 - val_loss: 0.4957 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1037 - accuracy: 0.9671 - val_loss: 0.3905 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9741 - val_loss: 0.5020 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0905 - accuracy: 0.9718 - val_loss: 0.5231 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0602 - accuracy: 0.9730 - val_loss: 0.4733 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0419 - accuracy: 0.9894 - val_loss: 0.4034 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0661 - accuracy: 0.9800 - val_loss: 0.5174 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0443 - accuracy: 0.9812 - val_loss: 0.5044 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 0.3981 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "213/213 [==============================] - 3s 13ms/step - loss: 0.0419 - accuracy: 0.9871 - val_loss: 0.3534 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9835 - val_loss: 0.4059 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0342 - accuracy: 0.9882 - val_loss: 0.4020 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0377 - accuracy: 0.9824 - val_loss: 0.4985 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0418 - accuracy: 0.9906 - val_loss: 0.5512 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0515 - accuracy: 0.9859 - val_loss: 0.4544 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0454 - accuracy: 0.9788 - val_loss: 0.7173 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0117 - accuracy: 0.9953 - val_loss: 0.5574 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.4435 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0531 - accuracy: 0.9847 - val_loss: 0.4485 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0465 - accuracy: 0.9859 - val_loss: 0.4353 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 47/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 0.5108 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0143 - accuracy: 0.9929 - val_loss: 0.5081 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0718 - accuracy: 0.9812 - val_loss: 0.7180 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9859 - val_loss: 0.4212 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0087 - accuracy: 0.9988 - val_loss: 0.3137 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "213/213 [==============================] - 3s 13ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.2761 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9941 - val_loss: 0.4021 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0373 - accuracy: 0.9882 - val_loss: 0.3907 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0510 - accuracy: 0.9800 - val_loss: 0.3429 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0326 - accuracy: 0.9871 - val_loss: 0.3845 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0123 - accuracy: 0.9953 - val_loss: 0.4103 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0307 - accuracy: 0.9918 - val_loss: 0.3554 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0124 - accuracy: 0.9953 - val_loss: 0.4004 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0483 - accuracy: 0.9871 - val_loss: 0.3189 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0154 - accuracy: 0.9953 - val_loss: 0.3738 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0278 - accuracy: 0.9906 - val_loss: 0.3433 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0563 - accuracy: 0.9847 - val_loss: 0.3401 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "213/213 [==============================] - 3s 14ms/step - loss: 0.0111 - accuracy: 0.9953 - val_loss: 0.2551 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 0.3477 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0823 - accuracy: 0.9824 - val_loss: 0.2641 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0155 - accuracy: 0.9965 - val_loss: 0.2792 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9965 - val_loss: 0.6296 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0197 - accuracy: 0.9953 - val_loss: 0.3814 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.4482 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9953 - val_loss: 0.3560 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 7.1748e-04 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0443 - accuracy: 0.9894 - val_loss: 0.3908 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0865 - accuracy: 0.9812 - val_loss: 0.4608 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0208 - accuracy: 0.9929 - val_loss: 0.5451 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0182 - accuracy: 0.9929 - val_loss: 0.3926 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0220 - accuracy: 0.9965 - val_loss: 0.4529 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0173 - accuracy: 0.9929 - val_loss: 0.3711 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9976 - val_loss: 0.3501 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0072 - accuracy: 0.9965 - val_loss: 0.4010 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "213/213 [==============================] - 2s 12ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.2432 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0466 - accuracy: 0.9882 - val_loss: 0.5175 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0424 - accuracy: 0.9835 - val_loss: 0.3549 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3210 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0382 - accuracy: 0.9941 - val_loss: 0.8534 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0666 - accuracy: 0.9871 - val_loss: 0.4571 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0145 - accuracy: 0.9953 - val_loss: 0.4644 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9953 - val_loss: 0.5126 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 89/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0166 - accuracy: 0.9965 - val_loss: 0.3554 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 90/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0371 - accuracy: 0.9941 - val_loss: 0.4281 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 91/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0195 - accuracy: 0.9941 - val_loss: 0.3554 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 92/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0459 - accuracy: 0.9859 - val_loss: 0.3338 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 93/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.4367 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 94/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9965 - val_loss: 0.7554 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 95/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0380 - accuracy: 0.9835 - val_loss: 0.2967 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 96/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.3517 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 97/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9847 - val_loss: 0.4753 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 98/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0142 - accuracy: 0.9965 - val_loss: 0.3579 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 99/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9965 - val_loss: 0.4981 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 100/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 0.1830 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 101/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0421 - accuracy: 0.9882 - val_loss: 0.4415 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 102/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.0345 - accuracy: 0.9906 - val_loss: 0.1732 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 103/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0432 - accuracy: 0.9859 - val_loss: 0.3096 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 104/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0263 - accuracy: 0.9929 - val_loss: 0.2849 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 105/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.3101 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 106/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9976 - val_loss: 0.2401 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 107/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.3423 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 108/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.3847 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 109/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0160 - accuracy: 0.9965 - val_loss: 0.3596 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 110/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9894 - val_loss: 0.4828 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 111/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0327 - accuracy: 0.9918 - val_loss: 0.3376 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 112/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0214 - accuracy: 0.9918 - val_loss: 0.2590 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 113/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0087 - accuracy: 0.9965 - val_loss: 0.3262 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 114/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9965 - val_loss: 0.4966 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 115/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0207 - accuracy: 0.9965 - val_loss: 0.4751 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 116/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9965 - val_loss: 0.3803 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 117/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0169 - accuracy: 0.9953 - val_loss: 0.6604 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 118/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.1059 - accuracy: 0.9730 - val_loss: 0.3417 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 119/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0524 - accuracy: 0.9847 - val_loss: 0.4177 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 120/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0148 - accuracy: 0.9953 - val_loss: 0.2045 - val_accuracy: 0.9531 - lr: 0.0010\n",
      "Epoch 121/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0382 - accuracy: 0.9929 - val_loss: 0.3462 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 122/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0053 - accuracy: 0.9976 - val_loss: 0.3749 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 123/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 124/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.4193 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 125/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 126/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9906 - val_loss: 0.4908 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 127/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.5059 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 128/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0512 - accuracy: 0.9906 - val_loss: 0.5004 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 129/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0086 - accuracy: 0.9965 - val_loss: 0.7494 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 130/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0119 - accuracy: 0.9953 - val_loss: 0.9756 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Epoch 131/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0102 - accuracy: 0.9965 - val_loss: 0.4445 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 132/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0312 - accuracy: 0.9906 - val_loss: 0.5086 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 133/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.9976 - val_loss: 0.3059 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 134/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0272 - accuracy: 0.9941 - val_loss: 0.5870 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 135/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0352 - accuracy: 0.9894 - val_loss: 0.5618 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 136/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0221 - accuracy: 0.9953 - val_loss: 0.3478 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 137/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0515 - accuracy: 0.9871 - val_loss: 0.4943 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 138/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0532 - accuracy: 0.9894 - val_loss: 0.2990 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 139/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.2671 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 140/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.2986 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 141/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0136 - accuracy: 0.9918 - val_loss: 0.4054 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 142/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0227 - accuracy: 0.9953 - val_loss: 0.5532 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 143/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0316 - accuracy: 0.9906 - val_loss: 0.4615 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 144/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0163 - accuracy: 0.9976 - val_loss: 0.7105 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 145/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0330 - accuracy: 0.9941 - val_loss: 0.5147 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 146/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0251 - accuracy: 0.9929 - val_loss: 0.4523 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 147/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.4024 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 148/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.2779 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 149/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 3.6924e-04 - accuracy: 1.0000 - val_loss: 0.2849 - val_accuracy: 0.9484 - lr: 0.0010\n",
      "Epoch 150/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.3643 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 151/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 8.7251e-05 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 152/200\n",
      "212/213 [============================>.] - ETA: 0s - loss: 2.4600e-04 - accuracy: 1.0000\n",
      "Epoch 00152: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 2.4560e-04 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9437 - lr: 0.0010\n",
      "Epoch 153/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 1.6438e-04 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 154/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 155/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.5661 - val_accuracy: 0.9202 - lr: 5.0000e-04\n",
      "Epoch 156/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0014 - accuracy: 0.9988 - val_loss: 0.3747 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 157/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 3.5471e-04 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 158/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.5434 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 159/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3275 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 160/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 1.2207e-04 - accuracy: 1.0000 - val_loss: 0.3216 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 161/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0108 - accuracy: 0.9976 - val_loss: 0.3154 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 162/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0254 - accuracy: 0.9953 - val_loss: 0.3943 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 163/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0183 - accuracy: 0.9953 - val_loss: 0.2685 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 7ms/step - loss: 9.2411e-04 - accuracy: 1.0000 - val_loss: 0.3618 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 165/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.2265 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 166/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0054 - accuracy: 0.9988 - val_loss: 0.2516 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 167/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0179 - accuracy: 0.9941 - val_loss: 0.2143 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 168/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0039 - accuracy: 0.9976 - val_loss: 0.2878 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 169/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 1.0905e-04 - accuracy: 1.0000 - val_loss: 0.2934 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 170/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9988 - val_loss: 0.4941 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 171/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0017 - accuracy: 0.9988 - val_loss: 0.5199 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 172/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.5526 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 173/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.4655 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 174/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.3724 - val_accuracy: 0.9577 - lr: 5.0000e-04\n",
      "Epoch 175/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 5.3500e-04 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 176/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 1.4431e-04 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 177/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 1.7507e-04 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 178/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 1.3547e-04 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 179/200\n",
      "213/213 [==============================] - 2s 8ms/step - loss: 0.0065 - accuracy: 0.9976 - val_loss: 0.6781 - val_accuracy: 0.9014 - lr: 5.0000e-04\n",
      "Epoch 180/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 9.7938e-04 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 181/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9976 - val_loss: 0.5459 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 182/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.3067 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 183/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0145 - accuracy: 0.9965 - val_loss: 0.3634 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 184/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0027 - accuracy: 0.9988 - val_loss: 0.2389 - val_accuracy: 0.9624 - lr: 5.0000e-04\n",
      "Epoch 185/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0026 - accuracy: 0.9988 - val_loss: 0.2469 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 186/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0199 - accuracy: 0.9976 - val_loss: 0.2896 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 187/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 6.4508e-04 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 188/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0021 - accuracy: 0.9988 - val_loss: 0.5464 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
      "Epoch 189/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0186 - accuracy: 0.9953 - val_loss: 0.3566 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 190/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 9.7377e-04 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 191/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 2.5113e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 192/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0150 - accuracy: 0.9965 - val_loss: 0.5582 - val_accuracy: 0.9061 - lr: 5.0000e-04\n",
      "Epoch 193/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9976 - val_loss: 0.6780 - val_accuracy: 0.9108 - lr: 5.0000e-04\n",
      "Epoch 194/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9976 - val_loss: 0.4604 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 195/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 5.5101e-04 - accuracy: 1.0000 - val_loss: 0.5194 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 196/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0015 - accuracy: 0.9988 - val_loss: 0.4655 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 197/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0110 - accuracy: 0.9941 - val_loss: 0.5123 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 198/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9976 - val_loss: 0.9485 - val_accuracy: 0.9061 - lr: 5.0000e-04\n",
      "Epoch 199/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.6858 - val_accuracy: 0.9061 - lr: 5.0000e-04\n",
      "Epoch 200/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0030 - accuracy: 0.9988 - val_loss: 0.6597 - val_accuracy: 0.9014 - lr: 5.0000e-04\n",
      "[INFO] confusion matrix:!\n",
      "[INFO] Loading best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96       106\n",
      "         1.0       0.95      0.96      0.96       107\n",
      "\n",
      "    accuracy                           0.96       213\n",
      "   macro avg       0.96      0.96      0.96       213\n",
      "weighted avg       0.96      0.96      0.96       213\n",
      "\n",
      "[INFO] Computing Confusion matrix\n",
      "conf_matrix.jpg is successfully saved!\n",
      "-----------------------------train 1 is done! ----------------------------------\n",
      "[INFO] Model:WaveletCustom is loaded ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 110, 110, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 108, 108, 8)       80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 107, 107, 8)       264       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 53, 53, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 53, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 16)        528       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 51, 51, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 23, 23, 32)        4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                991264    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,007,673\n",
      "Trainable params: 1,007,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Loading 2d data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] H.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,)\n",
      "[INFO] CHAN.shape: (1, 19)\n",
      "[INFO] Fs.shape: (1, 1)\n",
      "[INFO] healthy_samples: 14, schizo_samples: 14, channel_size: 19, and sub: 15000\n",
      "[INFO] normal samples: (532, 112, 112)\n",
      "[INFO] schizo samples: (532, 112, 112)\n",
      "[INFO] labels: (1064,)\n",
      "[INFO] data: (1064, 112, 112, 1)\n",
      "[INFO] x_train.shape: (851, 112, 112, 1), y_train.shape: (851,)\n",
      "[INFO] x_test.shape: (213, 112, 112, 1), y_test.shape: (213,)\n",
      "[INFO] Started the training for model: WaveletCustom ...\n",
      "[INFO] Saving params!\n",
      "[INFO] Params are successfully saved!\n",
      "[INFO] Training with the following arguments Namespace(seed=1236, model_name='WaveletCustom', data_path='./data/DATA.mat', epochs=200, batch_size=4, checkpoints='./checkpoints', early_stopping=100, reduce_lr=50, dir_name='2')\n",
      "Epoch 1/200\n",
      "213/213 [==============================] - 5s 14ms/step - loss: 0.6561 - accuracy: 0.6016 - val_loss: 0.5699 - val_accuracy: 0.6901 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.5140 - accuracy: 0.7427 - val_loss: 0.5290 - val_accuracy: 0.6948 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.4980 - accuracy: 0.7509 - val_loss: 0.4760 - val_accuracy: 0.7183 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4493 - accuracy: 0.7885 - val_loss: 0.4681 - val_accuracy: 0.7653 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.4228 - accuracy: 0.8096 - val_loss: 0.4335 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.3855 - accuracy: 0.8249 - val_loss: 0.4144 - val_accuracy: 0.8028 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.3439 - accuracy: 0.8437 - val_loss: 0.4617 - val_accuracy: 0.7700 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.3196 - accuracy: 0.8649 - val_loss: 0.4414 - val_accuracy: 0.8075 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2692 - accuracy: 0.8825 - val_loss: 0.4512 - val_accuracy: 0.8169 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2532 - accuracy: 0.8954 - val_loss: 0.4691 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2355 - accuracy: 0.9048 - val_loss: 0.4375 - val_accuracy: 0.8357 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2105 - accuracy: 0.9248 - val_loss: 0.4197 - val_accuracy: 0.8216 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1599 - accuracy: 0.9307 - val_loss: 0.4646 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.9495 - val_loss: 0.4829 - val_accuracy: 0.8638 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1140 - accuracy: 0.9542 - val_loss: 0.4787 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.1268 - accuracy: 0.9530 - val_loss: 0.3516 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1273 - accuracy: 0.9553 - val_loss: 0.3828 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0901 - accuracy: 0.9647 - val_loss: 0.4760 - val_accuracy: 0.8592 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0820 - accuracy: 0.9671 - val_loss: 0.4118 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.1049 - accuracy: 0.9647 - val_loss: 0.3439 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0456 - accuracy: 0.9847 - val_loss: 0.5322 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0521 - accuracy: 0.9871 - val_loss: 0.6114 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0789 - accuracy: 0.9741 - val_loss: 0.4137 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 24/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0808 - accuracy: 0.9765 - val_loss: 0.4367 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 25/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0542 - accuracy: 0.9765 - val_loss: 0.3428 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 26/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0957 - accuracy: 0.9694 - val_loss: 0.4219 - val_accuracy: 0.8685 - lr: 0.0010\n",
      "Epoch 27/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.4065 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 28/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0275 - accuracy: 0.9906 - val_loss: 0.4607 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 29/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0759 - accuracy: 0.9741 - val_loss: 0.4637 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 30/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0333 - accuracy: 0.9859 - val_loss: 0.3595 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 31/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9800 - val_loss: 0.4073 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 32/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9918 - val_loss: 0.6282 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 33/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0170 - accuracy: 0.9953 - val_loss: 0.5533 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 34/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0498 - accuracy: 0.9859 - val_loss: 0.3813 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 35/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0242 - accuracy: 0.9894 - val_loss: 0.3706 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 36/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9953 - val_loss: 0.4798 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 37/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.1553 - accuracy: 0.9495 - val_loss: 0.3059 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 38/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9847 - val_loss: 0.3585 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 39/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.4250 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 40/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0280 - accuracy: 0.9906 - val_loss: 0.4102 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 41/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 0.4352 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 42/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0676 - accuracy: 0.9800 - val_loss: 0.4166 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 43/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0213 - accuracy: 0.9894 - val_loss: 0.4724 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 44/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0290 - accuracy: 0.9941 - val_loss: 0.4966 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 45/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0226 - accuracy: 0.9918 - val_loss: 0.4308 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 46/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9777 - val_loss: 0.4825 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 47/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 6ms/step - loss: 0.1020 - accuracy: 0.9718 - val_loss: 0.3758 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 48/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9894 - val_loss: 0.5666 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 49/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0649 - accuracy: 0.9847 - val_loss: 0.4311 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 50/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.3496 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 51/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0189 - accuracy: 0.9906 - val_loss: 0.4061 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 52/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0322 - accuracy: 0.9882 - val_loss: 0.3746 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 53/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0375 - accuracy: 0.9906 - val_loss: 0.3870 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 54/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0122 - accuracy: 0.9965 - val_loss: 0.3861 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 55/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9988 - val_loss: 0.4387 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 56/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0146 - accuracy: 0.9929 - val_loss: 0.4509 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 57/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0423 - accuracy: 0.9871 - val_loss: 0.5221 - val_accuracy: 0.8732 - lr: 0.0010\n",
      "Epoch 58/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0739 - accuracy: 0.9835 - val_loss: 0.3732 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 59/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0452 - accuracy: 0.9894 - val_loss: 0.3653 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 60/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.4827 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 61/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0235 - accuracy: 0.9894 - val_loss: 0.6117 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 62/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0415 - accuracy: 0.9882 - val_loss: 0.6734 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 63/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9683 - val_loss: 0.4136 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 64/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0400 - accuracy: 0.9847 - val_loss: 0.5940 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 65/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0246 - accuracy: 0.9894 - val_loss: 0.5614 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 66/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0397 - accuracy: 0.9882 - val_loss: 0.5475 - val_accuracy: 0.9108 - lr: 0.0010\n",
      "Epoch 67/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.4867 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 68/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9941 - val_loss: 0.5693 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 69/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9976 - val_loss: 0.3619 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 70/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 71/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 72/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0206 - accuracy: 0.9929 - val_loss: 0.5268 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 73/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1063 - accuracy: 0.9753 - val_loss: 0.5699 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 74/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0338 - accuracy: 0.9859 - val_loss: 0.4633 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 75/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0400 - accuracy: 0.9871 - val_loss: 0.3916 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 76/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0156 - accuracy: 0.9929 - val_loss: 0.4169 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 77/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0101 - accuracy: 0.9953 - val_loss: 0.5356 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 78/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0385 - accuracy: 0.9859 - val_loss: 0.3179 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 79/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9953 - val_loss: 0.5891 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 80/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0156 - accuracy: 0.9906 - val_loss: 0.5783 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 81/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0192 - accuracy: 0.9941 - val_loss: 0.5063 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 82/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9953 - val_loss: 0.6382 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 83/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 84/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0575 - accuracy: 0.9824 - val_loss: 0.5358 - val_accuracy: 0.9249 - lr: 0.0010\n",
      "Epoch 85/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0542 - accuracy: 0.9788 - val_loss: 0.3871 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 86/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0185 - accuracy: 0.9929 - val_loss: 0.6133 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 87/200\n",
      "205/213 [===========================>..] - ETA: 0s - loss: 0.0120 - accuracy: 0.9988\n",
      "Epoch 00087: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9988 - val_loss: 0.5835 - val_accuracy: 0.9343 - lr: 0.0010\n",
      "Epoch 88/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0204 - accuracy: 0.9965 - val_loss: 0.4342 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 89/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0020 - accuracy: 0.9988 - val_loss: 0.4330 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 90/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0052 - accuracy: 0.9976 - val_loss: 0.5033 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 91/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9965 - val_loss: 0.4668 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 92/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 93/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9965 - val_loss: 0.4823 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 94/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9988 - val_loss: 0.4580 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 95/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9941 - val_loss: 0.5468 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 96/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0047 - accuracy: 0.9976 - val_loss: 0.6322 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 97/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.6688 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0062 - accuracy: 0.9988 - val_loss: 0.6937 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 99/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.6881 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 100/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 7.1876e-04 - accuracy: 1.0000 - val_loss: 0.6818 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 101/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9965 - val_loss: 0.4133 - val_accuracy: 0.9202 - lr: 5.0000e-04\n",
      "Epoch 102/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0202 - accuracy: 0.9965 - val_loss: 0.3103 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 103/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3180 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 104/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 3.2360e-04 - accuracy: 1.0000 - val_loss: 0.3249 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 105/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 106/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 107/200\n",
      "213/213 [==============================] - 2s 7ms/step - loss: 4.9298e-04 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 108/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.5330e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 109/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.4644 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 110/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.5725 - val_accuracy: 0.9531 - lr: 5.0000e-04\n",
      "Epoch 111/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 8.4245e-04 - accuracy: 1.0000 - val_loss: 0.5274 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 112/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9988 - val_loss: 0.7448 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 113/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.5715 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 114/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 6.0577e-04 - accuracy: 1.0000 - val_loss: 0.6964 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 115/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0196 - accuracy: 0.9965 - val_loss: 0.7791 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 116/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.8571 - val_accuracy: 0.9155 - lr: 5.0000e-04\n",
      "Epoch 117/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9988 - val_loss: 0.5389 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 118/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 0.9965 - val_loss: 0.5505 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 119/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 8.0633e-04 - accuracy: 1.0000 - val_loss: 0.5553 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 120/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.9837e-04 - accuracy: 1.0000 - val_loss: 0.5825 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 121/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 2.4399e-04 - accuracy: 1.0000 - val_loss: 0.6189 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 122/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 2.3065e-04 - accuracy: 1.0000 - val_loss: 0.5908 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 123/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 2.4530e-05 - accuracy: 1.0000 - val_loss: 0.5763 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 124/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 2.1698e-05 - accuracy: 1.0000 - val_loss: 0.5713 - val_accuracy: 0.9390 - lr: 5.0000e-04\n",
      "Epoch 125/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 3.3397e-05 - accuracy: 1.0000 - val_loss: 0.5730 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 126/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 3.8885e-05 - accuracy: 1.0000 - val_loss: 0.5565 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 127/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 4.7953e-04 - accuracy: 1.0000 - val_loss: 0.5720 - val_accuracy: 0.9437 - lr: 5.0000e-04\n",
      "Epoch 128/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 8.2936e-04 - accuracy: 1.0000 - val_loss: 0.5699 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 129/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 9.2609e-05 - accuracy: 1.0000 - val_loss: 0.6101 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 130/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0512 - accuracy: 0.9906 - val_loss: 0.5804 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 131/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9929 - val_loss: 0.4182 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 132/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 133/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0055 - accuracy: 0.9976 - val_loss: 0.4171 - val_accuracy: 0.9296 - lr: 5.0000e-04\n",
      "Epoch 134/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9941 - val_loss: 0.5517 - val_accuracy: 0.9249 - lr: 5.0000e-04\n",
      "Epoch 135/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0169 - accuracy: 0.9976 - val_loss: 0.5110 - val_accuracy: 0.9343 - lr: 5.0000e-04\n",
      "Epoch 136/200\n",
      "213/213 [==============================] - 1s 7ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.3216 - val_accuracy: 0.9624 - lr: 5.0000e-04\n",
      "Epoch 137/200\n",
      "203/213 [===========================>..] - ETA: 0s - loss: 0.0178 - accuracy: 0.9975\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0170 - accuracy: 0.9976 - val_loss: 0.3164 - val_accuracy: 0.9484 - lr: 5.0000e-04\n",
      "Epoch 00137: early stopping\n",
      "[INFO] confusion matrix:!\n",
      "[INFO] Loading best model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.90      0.91       106\n",
      "         1.0       0.90      0.93      0.91       107\n",
      "\n",
      "    accuracy                           0.91       213\n",
      "   macro avg       0.91      0.91      0.91       213\n",
      "weighted avg       0.91      0.91      0.91       213\n",
      "\n",
      "[INFO] Computing Confusion matrix\n",
      "conf_matrix.jpg is successfully saved!\n",
      "-----------------------------train 2 is done! ----------------------------------\n",
      "[INFO] Model:WaveletCustom is loaded ...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 110, 110, 1)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 108, 108, 8)       80        \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 107, 107, 8)       264       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 53, 53, 8)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 53, 53, 8)         0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 52, 52, 16)        528       \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 51, 51, 16)        1040      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 25, 25, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 24, 24, 32)        2080      \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 23, 23, 32)        4128      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 23, 23, 32)        0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 22, 22, 64)        8256      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 22, 22, 64)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 30976)             0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30976)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                991264    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,007,673\n",
      "Trainable params: 1,007,673\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Loading 2d data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] H.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,), each sample has (channels, values): (19, 180000) !\n",
      "[INFO] S.shape: (14,)\n",
      "[INFO] CHAN.shape: (1, 19)\n",
      "[INFO] Fs.shape: (1, 1)\n",
      "[INFO] healthy_samples: 14, schizo_samples: 14, channel_size: 19, and sub: 15000\n",
      "[INFO] normal samples: (532, 112, 112)\n",
      "[INFO] schizo samples: (532, 112, 112)\n",
      "[INFO] labels: (1064,)\n",
      "[INFO] data: (1064, 112, 112, 1)\n",
      "[INFO] x_train.shape: (851, 112, 112, 1), y_train.shape: (851,)\n",
      "[INFO] x_test.shape: (213, 112, 112, 1), y_test.shape: (213,)\n",
      "[INFO] Started the training for model: WaveletCustom ...\n",
      "[INFO] Saving params!\n",
      "[INFO] Params are successfully saved!\n",
      "[INFO] Training with the following arguments Namespace(seed=1237, model_name='WaveletCustom', data_path='./data/DATA.mat', epochs=200, batch_size=4, checkpoints='./checkpoints', early_stopping=100, reduce_lr=50, dir_name='3')\n",
      "Epoch 1/200\n",
      "213/213 [==============================] - 5s 14ms/step - loss: 0.6482 - accuracy: 0.6592 - val_loss: 0.6224 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.5235 - accuracy: 0.7438 - val_loss: 0.6247 - val_accuracy: 0.6667 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.4716 - accuracy: 0.7685 - val_loss: 0.5325 - val_accuracy: 0.7136 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.4156 - accuracy: 0.7967 - val_loss: 0.5120 - val_accuracy: 0.7512 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.3723 - accuracy: 0.8390 - val_loss: 0.4721 - val_accuracy: 0.7793 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.3282 - accuracy: 0.8508 - val_loss: 0.4027 - val_accuracy: 0.8404 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2944 - accuracy: 0.8660 - val_loss: 0.4717 - val_accuracy: 0.8310 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2668 - accuracy: 0.8825 - val_loss: 0.4570 - val_accuracy: 0.8263 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.9130 - val_loss: 0.4231 - val_accuracy: 0.8498 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.2027 - accuracy: 0.9189 - val_loss: 0.4308 - val_accuracy: 0.8545 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.1649 - accuracy: 0.9271 - val_loss: 0.6586 - val_accuracy: 0.7981 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "213/213 [==============================] - 3s 12ms/step - loss: 0.1888 - accuracy: 0.9307 - val_loss: 0.3463 - val_accuracy: 0.8920 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9424 - val_loss: 0.4935 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1282 - accuracy: 0.9530 - val_loss: 0.3652 - val_accuracy: 0.9014 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1267 - accuracy: 0.9436 - val_loss: 0.3698 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1111 - accuracy: 0.9577 - val_loss: 0.3657 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 17/200\n",
      "213/213 [==============================] - 2s 10ms/step - loss: 0.0883 - accuracy: 0.9683 - val_loss: 0.3001 - val_accuracy: 0.9155 - lr: 0.0010\n",
      "Epoch 18/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.0695 - accuracy: 0.9765 - val_loss: 0.4136 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 19/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1074 - accuracy: 0.9577 - val_loss: 0.3774 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 20/200\n",
      "213/213 [==============================] - 1s 6ms/step - loss: 0.0991 - accuracy: 0.9683 - val_loss: 0.3285 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 21/200\n",
      "213/213 [==============================] - 2s 11ms/step - loss: 0.0647 - accuracy: 0.9753 - val_loss: 0.2754 - val_accuracy: 0.9202 - lr: 0.0010\n",
      "Epoch 22/200\n",
      "213/213 [==============================] - 1s 5ms/step - loss: 0.1182 - accuracy: 0.9612 - val_loss: 0.3129 - val_accuracy: 0.9061 - lr: 0.0010\n",
      "Epoch 23/200\n",
      "204/213 [===========================>..] - ETA: 0s - loss: 0.0641 - accuracy: 0.9804"
     ]
    }
   ],
   "source": [
    "csv_files = []\n",
    "for n in range(multi_train):\n",
    "    dir_name = f\"{n}\"\n",
    "    new_seed = seed + n\n",
    "    # preserve reproducibility\n",
    "    !PYTHONHASHSEED=0\n",
    "    !TF_DETERMINISTIC_OPS=0\n",
    "    !TF_CUDNN_DETERMINISTIC=0\n",
    "    !python train.py --model-name $model_name --epochs $epochs --seed $new_seed --dir-name $dir_name --checkpoints $checkpoints --batch-size $batch_size\n",
    "    print(f\"-----------------------------train {n} is done! ----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0977a1b7",
   "metadata": {
    "id": "0977a1b7"
   },
   "source": [
    "# Get Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf3098",
   "metadata": {
    "id": "34cf3098",
    "outputId": "d581a2c5-f802-4e46-ebdb-8f9220da1b11",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from utils.group_metrics import get_mean_std\n",
    "import os\n",
    "\n",
    "csv_files = [os.path.join(checkpoints, model_name ,f\"{n}\", \"log.csv\") for n in range(multi_train)]\n",
    "metrics = get_mean_std(csv_files, \n",
    "                       arguments=(\"accuracy\", \"loss\", \"val_accuracy\", \"val_loss\"),\n",
    "                       operators=(max, min, max, min)\n",
    "                      )\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7e53a2",
   "metadata": {
    "id": "be7e53a2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
